{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple neural network from scratch\n",
    "\n",
    "This uses only numpy. Kudos to Niko Steinhoff (nsteinhoff on github) for developing the base for this on his phone and @iamtrask for the original code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This module implements a simple neural network with\n",
    "variable number of hidden layers.\n",
    "\n",
    "Todo:\n",
    "    - create larger dataset\n",
    "    - split train and test set\n",
    "    - check test error per iteration\n",
    "    - propper gradient descent\n",
    "    - regularization\n",
    "    - mini-batch\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "- We need a functions that calculates the sigmoid a a given number of array (This means projecting a natural number on the space [0,1] using an exponential function).\n",
    "- We need the derivative of our function. As the function we use is the logistic function, it's derivative is x\\*(1-x) if x is the result of the logistic function.\n",
    "- The transform function is needed to turn the dot product of the x and the weights into a sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def derivative(x):\n",
    "    return x * (1-x)\n",
    "\n",
    "def transform(x, w):\n",
    "    return sigmoid(np.dot(x, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_weights(n_inputs, n_outputs, seed=123):\n",
    "    np.random.seed(seed)\n",
    "    return 2 * np.random.random((n_inputs, n_outputs)) - 1\n",
    "    \n",
    "def initialize_model(layers, seed=123):\n",
    "    in_out = [(i, o) for i, o in zip(layers, layers[1:] + [1])]\n",
    "    l = [initialize_weights(n_in, n_out, seed+i)\n",
    "         for i, (n_in, n_out) in enumerate(in_out)]   \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def apply_model(model, x):\n",
    "    out = [x]\n",
    "    for i, w in enumerate(model):\n",
    "        out.append(transform(out[i], w))\n",
    "    return out\n",
    "\n",
    "def update_model(model, outputs, y):\n",
    "    error = y - outputs[-1]\n",
    "    slope = derivative(outputs[-1])\n",
    "    update = error * slope \n",
    "    new_weight = model[-1] + np.dot(outputs[-2].T, update)\n",
    "    \n",
    "    updates = [update]\n",
    "    new_weights = [new_weight]\n",
    "    \n",
    "    for i in range(len(model)-1):\n",
    "        upstream = -(i+1)\n",
    "        this = upstream - 1\n",
    "        downstream = this - 1\n",
    "        \n",
    "        back_prop = np.dot(updates[i], model[upstream].T)\n",
    "        update = back_prop * derivative(outputs[this])\n",
    "        new_weight = model[this] + np.dot(outputs[downstream].T, update)\n",
    "        \n",
    "        updates.append(update)\n",
    "        new_weights.append(new_weight)\n",
    "        \n",
    "    return list(reversed(new_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X, y, hidden_layers=None, n_iter=1000):\n",
    "    print(\"Training neural network... \")\n",
    "    n_input = X.shape[1]\n",
    "    if hidden_layers is None:\n",
    "        hidden_layers = []\n",
    "    layers = [n_input] + hidden_layers\n",
    "    model = initialize_model(layers)\n",
    "    \n",
    "    print(\"Initial model:\")\n",
    "    for i, m in enumerate(model):\n",
    "        print(\"Layer {}:\".format(i+1))\n",
    "        print(m)\n",
    "        \n",
    "    errors = []\n",
    "    scores = []\n",
    "    for _ in range(n_iter):\n",
    "        out = apply_model(model, X)\n",
    "        model = update_model(model, out, y)\n",
    "        \n",
    "        y_proba = out[-1]\n",
    "        y_pred = (y_proba >= 0.5).astype('int')\n",
    "        error = np.mean(np.abs(y - y_proba))\n",
    "        accuracy = np.mean(y_pred == y)\n",
    "        errors.append(error)\n",
    "        scores.append(accuracy)\n",
    "\n",
    "    stats = zip(scores, errors)\n",
    "    interval = len(scores)/10\n",
    "    print('')\n",
    "    print(\"{:<6}: {:>4} {:>8}\".format('iter', 'acc', 'err'))\n",
    "    for i, s in enumerate(stats[::interval]):\n",
    "        print(\"{:<6}: {:>4.2f} {:>8.4f}\".format(i*interval, *s))\n",
    "    plt.plot(errors)\n",
    "    plt.show()\n",
    "    \n",
    "    print('')\n",
    "    print(\"After training {} iterations:\\nTrue vs. Pred\".format(n_iter))\n",
    "    print(np.column_stack((y, y_proba)))\n",
    "    print('')\n",
    "    print(\"Accuracy: {:>10.2f}\".format(accuracy))\n",
    "    print(\"Error:    {:>10.4f}\".format(error))\n",
    "    print('')\n",
    "    print(\"Final model:\")\n",
    "    for i, m in enumerate(model):\n",
    "        print(\"Layer {}:\".format(i+1))\n",
    "        print(m)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model, X, y):\n",
    "    print('')\n",
    "    print(\"Testing neural network... \")\n",
    "    out = apply_model(model, X)\n",
    "    y_proba = out[-1]\n",
    "    y_pred = (y_proba >= 0.5).astype('int')\n",
    "    error = np.mean(np.abs(y - y_proba))\n",
    "    accuracy = np.mean(y_pred == y)\n",
    "    print(\"Accuracy: {:>10.2f}\".format(accuracy))\n",
    "    print(\"Error:    {:>10.4f}\".format(error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "+=====+ START +======+\n",
      "Training neural network... \n",
      "Initial model:\n",
      "Layer 1:\n",
      "[[ 0.39293837 -0.42772133 -0.54629709  0.10262954]\n",
      " [ 0.43893794 -0.15378708  0.9615284   0.36965948]\n",
      " [-0.0381362  -0.21576496 -0.31364397  0.45809941]]\n",
      "Layer 2:\n",
      "[[-0.78787019  0.49094297  0.14462707]\n",
      " [-0.08351763 -0.23058819 -0.45202139]\n",
      " [ 0.33592482 -0.20904998 -0.43685421]\n",
      " [ 0.55983941  0.19818833 -0.75410728]]\n",
      "Layer 3:\n",
      "[[ 0.01345202]\n",
      " [-0.88493861]\n",
      " [ 0.25515997]]\n",
      "\n",
      "iter  :  acc      err\n",
      "0     : 0.40   0.5205\n",
      "1000  : 1.00   0.0191\n",
      "2000  : 1.00   0.0120\n",
      "3000  : 1.00   0.0094\n",
      "4000  : 1.00   0.0079\n",
      "5000  : 1.00   0.0070\n",
      "6000  : 1.00   0.0063\n",
      "7000  : 1.00   0.0058\n",
      "8000  : 1.00   0.0053\n",
      "9000  : 1.00   0.0050\n"
     ]
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAFHdJREFUeJzt3X/wXXdd5/Hni2+aUij2BzitJNGgrUpXQHBJK/6KUCWw\n",
       "O4TZ1QlV664wTsedKLu6a6izI5nZdUb8gSzTESN2nV1GDS5iSWcpFYTojgJtNZZWkpJQMybpUKCF\n",
       "UmgLSfveP875Njdfbr/3fpN777n5nudj5sy955zPvZ/P/WTyOp/v555zbqoKSVJ/PK3rBkiSZsvg\n",
       "l6SeMfglqWcMfknqGYNfknrG4JeknhkZ/Em2JDmQ5GCSHU9RZnOSfUnuTrJ34q2UJE1MljuPP8kC\n",
       "cA9wNXAMuB24pqr2D5S5EPgb4JVVdTTJc6rq89NttiTpdI0a8W8CDlXV4ao6DuwGti4p8xPAn1XV\n",
       "UQBDX5Lm26jgXwccGVg/2m4bdDlwcZKPJLkjybWTbKAkabLWjNg/zv0czgFeArwCeAbw0SQfq6qD\n",
       "Z9o4SdLkjQr+Y8CGgfUNNKP+QUeAz1fVo8CjSf4aeBFwSvAn8aZAknQaqiqTfL9RwX8HcHmSjcB9\n",
       "wDbgmiVl3gfc0H4RfC5wJfDWYW826cafrZLsrKqdXbdjHtgXJ9kXJ9kXJ01j0Lxs8FfViSTbgVuB\n",
       "BeDGqtqf5Lp2/66qOpDkA8AngCeAd1bVJyfdUEnSZIwa8VNVtwC3LNm2a8n6bwG/NdmmSZKmwSt3\n",
       "u7G36wbMkb1dN2CO7O26AXNkb9cNWM2WvYBrohUl5Ry/JK3MNLLTEb8k9YzBL0k9Y/BLUs8Y/JLU\n",
       "Mwa/JPWMwS9JPWPwS1LPGPyS1DMGvyT1jMEvST1j8EtSzxj8ktQzBr8k9YzBL0k9Y/BLUs8Y/JLU\n",
       "Mwa/JPWMwS9JPWPwS1LPGPyS1DMGvyT1jMEvST1j8EtSzxj8ktQzBr8k9YzBL0k9MzL4k2xJciDJ\n",
       "wSQ7huzfnOShJPva5b9Op6mSpElYs9zOJAvADcDVwDHg9iR7qmr/kqJ/VVWvmVIbJUkTNGrEvwk4\n",
       "VFWHq+o4sBvYOqRcJt4ySdJUjAr+dcCRgfWj7bZBBbwsyZ1J3p/kikk2UJI0WctO9dCE+ih/D2yo\n",
       "qkeSvAq4Cfj2M26ZJGkqRgX/MWDDwPoGmlH/k6rq4YHntyT53SQXV9WDS98syc6B1b1VtXfFLZak\n",
       "VSzJZmDzVOuoeupBfZI1wD3AK4D7gNuAawa/3E1yCfDZqqokm4A/raqNQ96rqsrvAiRpBaaRncuO\n",
       "+KvqRJLtwK3AAnBjVe1Pcl27fxfwY8DPJTkBPAK8bpINlCRN1rIj/olW5IhfklZsGtnplbuS1DMG\n",
       "vyT1zEyDP/FCL0nq2qxH/G+ccX2SpCVmHfz/OeFHZlynJGnArIN/O/BrM65TkjRgpqdzQq2huRDs\n",
       "ZVV8eiYVS9JZ7Kw/nbOKx4EPAj80y3olSSd1cTrnPuDFHdQrSaKb4L8beH4H9UqS6Cb4jwDrO6hX\n",
       "kkR3wb/Bi7kkqRszD/4qHgYeBy6Ydd2SpO7u1fMgcFFHdUtSr3UV/F8ALuyobknqta6C/4s44pek\n",
       "Tjjil6SeccQvST3TVfB/BXhGR3VLUq91FfyPYvBLUie6Cv5HgPM6qluSes0RvyT1TJfB74hfkjrg\n",
       "VI8k9YxTPZLUM071SFLPdDnV44hfkjrQVfB/FVjbUd2S1GtdBf9xDH5J6sTI4E+yJcmBJAeT7Fim\n",
       "3EuTnEjyb8ao92sY/JLUiWWDP8kCcAOwBbgCuCbJ1/1QelvuLcAHYKyfVDwOnLPi1kqSztioEf8m\n",
       "4FBVHa6q48BuYOuQcj8PvAf43Jj1OuKXpI6MCv51ND+Ovuhou+1JSdbRHAze0W6qMer9Go74JakT\n",
       "a0bsHyfE3wa8qaoqSVhmqifJzubZ+gvhD54FrxyzmZLUD0k2A5unWkfVU2d7kquAnVW1pV2/Hnii\n",
       "qt4yUOZeTob9c2jO0f/Zqtqz5L2qqtI857nAHVU8d5IfRpJWm8HsnJRRI/47gMuTbATuA7YB1wwW\n",
       "qKpvHWjgHwI3Lw39ITydU5I6smzwV9WJJNuBW4EF4Maq2p/kunb/rtOs1zl+SerIslM9E63o1Kme\n",
       "ZwAPVHm/HklazjSmerq6ctfTOSWpI10F/+NAEhY6ql+SequT4K+i8OpdSepEVyN+8AteSepEl8Hv\n",
       "KZ2S1AFH/JLUM474Jalnuh7xG/ySNGNdj/id6pGkGesy+E8w+l5BkqQJc8QvST1j8EtSzxj8ktQz\n",
       "Br8k9YzBL0k9Y/BLUs8Y/JLUMwa/JPWMwS9JPWPwS1LPdB383rJBkmas6+B3xC9JM9b1TdoMfkma\n",
       "MUf8ktQzBr8k9YzBL0k9Y/BLUs8Y/JLUMyODP8mWJAeSHEyyY8j+rUnuTLIvyd8lefmYdRv8ktSB\n",
       "ZS+gSrIA3ABcDRwDbk+yp6r2DxT7UFW9ry3/AuDPgcvGqNvgl6QOjBrxbwIOVdXhqjoO7Aa2Dhao\n",
       "qq8MrJ4PfH7Mug1+SerAqOBfBxwZWD/abjtFktcm2Q/cAvzCmHV7ywZJ6sCo4K1x3qSqbgJuSvID\n",
       "wLuA7xhWLsnOk2u/fh7scMQvSQOSbAY2T7OOUcF/DNgwsL6BZtQ/VFX9vyRrkjy7qh4Ysn/n4vOE\n",
       "a4EfXVlzJWl1q6q9wN7F9SRvnnQdo6Z67gAuT7IxyVpgG7BnsECSb0uS9vlLAIaF/hDeq0eSOrDs\n",
       "iL+qTiTZDtwKLAA3VtX+JNe1+3cB/xb46STHgS8Drxuzbr/claQOpGqsafwzryipqsrJdbYCb6ji\n",
       "NTNpgCSdhZZm5yR45a4k9YzBL0k9Y/BLUs8Y/JLUMwa/JPVM18HvLRskaca6Dn5H/JI0Ywa/JPWM\n",
       "wS9JPWPwS1LPdBn83qRNkjrgiF+Sesbgl6SeMfglqWcMfknqma6/3F1ImOh9piVJy+ss+KsomvD3\n",
       "tg2SNENdjvjB6R5JmjmDX5J6xuCXpJ4x+CWpZwx+SeoZg1+Seqbr4PdGbZI0Y10HvyN+SZoxg1+S\n",
       "emYegt8rdyVphuYh+B3xS9IMjRX8SbYkOZDkYJIdQ/b/ZJI7k3wiyd8keeGY9Rv8kjRjI4M/yQJw\n",
       "A7AFuAK4JsnzlxS7F/jBqnoh8N+A3x+zfoNfkmZsnBH/JuBQVR2uquPAbmDrYIGq+mhVPdSufhxY\n",
       "P2b9Br8kzdg4wb8OODKwfrTd9lTeALx/zPoNfkmasXHOqKlx3yzJDwOvB77vKfbvHFjdC2XwS9KA\n",
       "JJuBzdOsY5zgPwZsGFjfQDPqP0X7he47gS1V9YVhb1RVO099Dddh8EvSk6pqL7B3cT3JmyddxzhT\n",
       "PXcAlyfZmGQtsA3YM1ggyTcD7wV+qqoOraB+R/ySNGMjR/xVdSLJduBWYAG4sar2J7mu3b8L+FXg\n",
       "IuAdSQCOV9WmMer3Xj2SNGOpGnsK/8wqSqqqcuo2dgH7qvi9mTRCks4yw7LzTM3DlbveskGSZmge\n",
       "gt+pHkmaIYNfknrG4JeknjH4Jalnug7+x4Cnd9wGSeqVroP/UeC8jtsgSb3SdfA/Ajyj4zZIUq90\n",
       "HfyO+CVpxroOfkf8kjRjXQe/I35JmrGug98RvyTNWNfB74hfkmas6+B3xC9JM9Z18D+KwS9JMzUP\n",
       "we9UjyTNUNfB71SPJM1Y18HviF+SZqzr4P8asJD4K1ySNCudBn8VBXwFeGaX7ZCkPul6xA/wJeAb\n",
       "um6EJPXFPAT/Q8CFXTdCkvpiXoL/gq4bIUl9YfBLUs8Y/JLUMwa/JPWMwS9JPTMPwf9FDH5Jmpmx\n",
       "gj/JliQHkhxMsmPI/u9M8tEkjyX5pRW2wRG/JM3QyFslJFkAbgCuBo4BtyfZU1X7B4o9APw88NrT\n",
       "aMODwLNP43WSpNMwzoh/E3Coqg5X1XFgN7B1sEBVfa6q7gCOn0Yb7gcuOY3XSZJOwzjBvw44MrB+\n",
       "tN02KQa/JM3QOMFfU27D/cClU65DktQa53bIx4ANA+sbaEb9K5Zk58Dq3qraSzPH/8yEc6v46um8\n",
       "ryStFkk2A5unWkfV8gP6JGuAe4BXAPcBtwHXLPlyd7HsTuDhqvrtIfuqqjK8Do4BV1WdMqUkSb23\n",
       "XHaerpEj/qo6kWQ7cCuwANxYVfuTXNfu35XkUuB2mtsrP5HkjcAVVfXlMduxON1j8EvSlI0c8U+s\n",
       "ouVH/O8F/qSK/zOTxkjSWWIaI/55uHIX4F7gW7tuhCT1gcEvST0zL8H/aQx+SZqJeQr+y7puhCT1\n",
       "wbwE/z8B35h4szZJmra5CP4qHgfuAl7UdVskabWbi+Bv7QNe3HUjJGm1m6fg/zvgpV03QpJWu3kK\n",
       "/o8AL0+Y6IUKkqRTzU3wV3Ev8BhwRddtkaTVbG6Cv/VB4NVdN0KSVrN5C/7dwE903QhJWs3mLfj/\n",
       "CnhOwgu6bogkrVZzFfxVPAHsAn6x67ZI0mo1F7dlPrUcFwGHgJe2X/hKUm+t5tsyP6mKLwBvBd7u\n",
       "qZ2SNHlzF/yt3wSeB/x01w2RpNVm7qZ6Tpbnu2gu6vpXVdw2vZZJ0vzqxVTPoiruBl4P3Jywqev2\n",
       "SNJqMbfBD1DFzcAbgP+bcG3X7ZGk1WBup3pOfS0vAN4DfAL4T1UcnWjjJGlO9WqqZ1AVdwHfDewH\n",
       "7kx4a8K6jpslSWelsyL4Aap4tIpf5eSPtdyd8OcJr01Y22XbJOlsclZM9Qx/P74B+HHg3wEvpDkD\n",
       "6Bbgw8Cnq5jNB5OkKZrGVM9ZG/ynvjffCLwSeBXwg8C5wMfa5S7gH4HD7S0hJOmsYfCPXRfrge8F\n",
       "rgS+C/gXwEXAAeBTND/ufnhg+ecqvjqLtknSShj8Z1Q/F9D8yMtlwEaaK4M3tst64CHgfuAzS5b7\n",
       "gQeAB4EvLC5VHJ9l+yX1k8E/JQkLwLOBS59iubhdLmqXC4FHaQ4CiweELwEPA18e8jhs2yPtezwK\n",
       "PFbFiel/Uklnm06CP8kW4G3AAvAHVfWWIWXeTjO//gjw76tq35Aycxv8K5XwNOBZnDwQXNyuPws4\n",
       "v12GPR98PG/J8gTtQYCBA8Iyzx8DjgNfG2MZp9zxgccTS5bH/bJc6sY0snPNiAoXgBuAq4FjwO1J\n",
       "9lTV/oEyrwYuq6rLk1wJvAO4apKNnDftl8QPtcvhlb4+yeaq2ntyndD8WyweBJ7OqQeFpw95fi6w\n",
       "dsly/pBtg8s5I/avbduxdFlIeJyBAwFff3BYyTLw+ndfDNvua9efaPeNehynzLTfY3GpIc+XPo65\n",
       "7zu+D+7561Gv68NBeOn/EU3WssEPbAIOVdVhgCS7ga00F1Iteg3wvwCq6uNJLkxySVXdP4X2rhab\n",
       "gb2LK+1/5OPt8qVumvTU2gPTAkMOCEO2rWRZgN/fBts+RHNQelq7LCzzOPh87Yiy47zHmTxmoM0Z\n",
       "8TjGvh8/j+avruVelzRjvwkecFa0b/BxnIUVlB1Yfu6yhE+t8HWnWddpLbOua6JGBf864MjA+lGa\n",
       "M2VGlVlP86WoVoH2wLQ4Wp+o5MNXVPG/J/2+Z6Pk13ZW/fedo8tN+oBz2vtGLYxZbshy508Cf7KC\n",
       "15xBXSteJlHXuH04lenxUcE/7tFmaeNW/Z+iUlfaA/HidNWqlPztS9ubNPZewi9N+j1HBf8xYMPA\n",
       "+gb4uhukLS2zvt32dZJ4QGgleXPXbZgX9sVJ9sVJ9sX0jAr+O4DLk2wE7gO2AdcsKbMH2A7sTnIV\n",
       "8MVh8/ur5YweSTrbLRv8VXUiyXbgVpovtG6sqv1Jrmv376qq9yd5dZJDwFeAn5l6qyVJp21mF3BJ\n",
       "kubD1G/LnGRLkgNJDibZMe36upBkQ5KPJPnHJHcn+YV2+8VJPpjkU0n+IsmFA6+5vu2TA0l+dGD7\n",
       "9yS5q933P7r4PJOQZCHJviQ3t+u97Iv29Ob3JNmf5JNJruxxX1zf/h+5K8kfJzm3L32R5H8muT/J\n",
       "XQPbJvbZ2758d7v9Y0m+ZdkGVdXUFprpoUM098M5B/gH4PnTrLOLhea2Dt/dPj8fuAd4PvAbwC+3\n",
       "23cAv94+v6Lti3PavjnEyb++bgM2tc/fD2zp+vOdZp/8IvBHwJ52vZd9QXONy+vb52uAC/rYF+3n\n",
       "uRc4t11/N80t1XvRF8APAC8G7hrYNrHPDvwH4Hfb59uA3cu2Z8of9nuBDwysvwl4U9f/CDP4R76J\n",
       "5mrnA8Al7bZLgQPt8+uBHQPlP0BztfM3AfsHtr8O+L2uP89pfP71wIeAHwZubrf1ri/akL93yPY+\n",
       "9sXFNAOii2gOgDcDP9KnvmhDfDD4J/bZ2zJXts/XAJ9bri3TnuoZdnHXqv7JxPYMqBcDH6f5R108\n",
       "w+l+4JL2+XM59bTYxX5Zuv0YZ2d//Q7wX+CU3z/oY188D/hckj9M8vdJ3pnkmfSwL6rqQeC3gX+m\n",
       "OUPwi1X1QXrYFwMm+dmfzNqqOgE8lOTip6p42sHfq2+Ok5wP/Bnwxqp6eHBfNYfiVd8fSf418Nlq\n",
       "btQ39BTevvQFzcjrJTR/gr+E5qy3Nw0W6EtfJPk24D/SjHqfC5yf5KcGy/SlL4aZ9WefdvCPcwHY\n",
       "qpDkHJrQf1dV3dRuvj/Jpe3+bwI+224fdtHb0Xb7+iXbh14MN8deBrwmyT/RXHL/8iTvop99cRQ4\n",
       "WlW3t+vvoTkQfKaHffEvgb+tqgfaEel7aaaC+9gXiybxf+LowGu+uX2vNcAF7V9ZQ007+J+8ACzJ\n",
       "WpovHfZMuc6ZSxLgRuCTVfW2gV17aL7Aon28aWD765KsTfI84HLgtqr6DPCl9syPANcOvOasUFW/\n",
       "UlUbqup5NHOQH66qa+lnX3wGOJLk29tNV9P8DOjN9KwvaOazr0pyXvsZrgY+ST/7YtEk/k+8b8h7\n",
       "/Rjwl8vWPIMvNF5F86XOIeD6rr9gmdJn/H6a+ex/APa1yxaaL7Q+RPNzj38BXDjwml9p++QA8MqB\n",
       "7d9D8zvBh4C3d/3ZzrBffoiTZ/X0si+AFwG3A3fSjHIv6HFf/DLNge8umrOdzulLX9D89Xsfzd1X\n",
       "j9Bc6Dqxz05zm/Y/BQ7S/Nb4xuXa4wVcktQzU7+AS5I0Xwx+SeoZg1+Sesbgl6SeMfglqWcMfknq\n",
       "GYNfknrG4Jeknvn/sJOJ0b4ucFoAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f00c990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After training 10000 iterations:\n",
      "True vs. Pred\n",
      "[[ 0.          0.00661533]\n",
      " [ 0.          0.0053977 ]\n",
      " [ 1.          0.99857332]\n",
      " [ 1.          0.99760633]\n",
      " [ 1.          0.99223217]]\n",
      "\n",
      "Accuracy:       1.00\n",
      "Error:        0.0047\n",
      "\n",
      "Final model:\n",
      "Layer 1:\n",
      "[[ 3.36734717 -2.00270805 -2.58223472 -2.2405925 ]\n",
      " [ 0.04888636  0.30219746  0.94114509  0.43121706]\n",
      " [-2.88819152  1.50998857  1.67939996  1.93694481]]\n",
      "Layer 2:\n",
      "[[-3.79165409 -0.48580832  6.94053974]\n",
      " [ 0.28182997  0.36885226 -0.87063071]\n",
      " [ 0.83707396  0.53063077 -1.37202519]\n",
      " [ 1.20463477  0.8630214  -1.14148084]]\n",
      "Layer 3:\n",
      "[[-5.05870013]\n",
      " [-1.65578295]\n",
      " [ 8.85367446]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n+{:=^20}+\".format('+ START +'))\n",
    "X = np.array([[0, 0, 1],\n",
    "                  [0, 1, 1],\n",
    "                  [1, 0, 1],\n",
    "                  [1, 1, 1],\n",
    "                  [0, 0, 0]])\n",
    "y = np.array([0, 0, 1, 1, 1]).reshape((-1 , 1))\n",
    "\n",
    "model = train(X, y, hidden_layers=[4, 3], n_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
